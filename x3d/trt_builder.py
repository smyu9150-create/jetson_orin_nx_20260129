import torch
import torch_tensorrt
import sys
import torchvision.transforms.functional as F

sys.modules["torchvision.transforms.functional_tensor"] = F

def build():
    print("ğŸš€ [Step 1] PyTorch ëª¨ë¸ ë¡œë“œ...")
    model_name = 'x3d_s'
    
    # 1. ëª¨ë¸ ë¡œë“œ
    model = torch.hub.load('facebookresearch/pytorchvideo', model_name, pretrained=True)
    
    # [í•µì‹¬ ìˆ˜ì • 1] .to(memory_format=torch.channels_last_3d) ì¶”ê°€!
    # ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ ì €ì¥ ìˆœì„œë¥¼ ë¯¸ë¦¬ GPU ì¹œí™”ì ìœ¼ë¡œ ë°”ê¿‰ë‹ˆë‹¤.
    model = model.eval().cuda().half().to(memory_format=torch.channels_last_3d)

    print("ğŸ›  [Step 2] Channels Last ìµœì í™” ì»´íŒŒì¼ ì‹œì‘...")

    # X3D-S ì…ë ¥ ê·œê²©
    trt_input_shape = [1, 3, 13, 182, 182]

    # [í•µì‹¬ ìˆ˜ì • 2] ì…ë ¥ ë°ì´í„° ì •ì˜ ì‹œì—ë„ format ëª…ì‹œ ê¶Œì¥
    # (Torch-TensorRTê°€ ì•Œì•„ì„œ ì²˜ë¦¬í•˜ê¸´ í•˜ì§€ë§Œ, ëª¨ë¸ì´ ì´ë¯¸ ë³€í™˜ë˜ì–´ ìˆì–´ì•¼ í•¨)
    
    trt_model = torch_tensorrt.compile(
        model,
        inputs=[torch_tensorrt.Input(
            min_shape=trt_input_shape,
            opt_shape=trt_input_shape,
            max_shape=trt_input_shape,
            dtype=torch.half,
            name="input_video",
            # ì…ë ¥ í…ì„œì˜ ë©”ëª¨ë¦¬ í¬ë§· íŒíŠ¸ ì œê³µ
            format=torch.channels_last_3d 
        )],
        enabled_precisions={torch.half},
        truncate_long_and_double=True,
        workspace_size=1 << 30 # ë©”ëª¨ë¦¬ ì¡°ê¸ˆ ë” ë„‰ë„‰í•˜ê²Œ (1GB)
    )
    
    print("ğŸ“¦ [Step 3] ì €ì¥ í˜¸í™˜ì„±ì„ ìœ„í•œ Trace...")
    
    # [í•µì‹¬ ìˆ˜ì • 3] ë”ë¯¸ ì…ë ¥ë„ channels_last_3dë¡œ ìƒì„±
    dummy_input = torch.randn(trt_input_shape).cuda().half().to(memory_format=torch.channels_last_3d)
    traced_model = torch.jit.trace(trt_model, [dummy_input])

    print("ğŸ’¾ [Step 4] ì €ì¥ (x3d_xs_trt_fp16_nhwc.ts)...")
    torch.jit.save(traced_model, "x3d_xs_trt_fp16_nhwc.ts")
    
    print("âœ… ìµœì í™” ë¹Œë“œ ì™„ë£Œ!")

if __name__ == "__main__":
    build()