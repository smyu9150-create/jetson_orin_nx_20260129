import torch
import torch_tensorrt  # noqa: F401 (ë¡œë“œë§Œ í•´ë„ ì—”ì§„ ì‹¤í–‰ì— í•„ìš”í•  ìˆ˜ ìˆìŒ)
import sys
import os
import glob
import time
import json
import urllib.request
import torchvision.transforms.functional as F
import numpy as np

# ----------------- [ê¸´ê¸‰ íŒ¨ì¹˜] -----------------
sys.modules["torchvision.transforms.functional_tensor"] = F
# ------------------------------------------------

from pytorchvideo.data.encoded_video import EncodedVideo
from torchvision.transforms import Compose, Lambda
from torchvision.transforms._transforms_video import CenterCropVideo, NormalizeVideo
from pytorchvideo.transforms import ApplyTransformToKey, ShortSideScale, UniformTemporalSubsample

# ==========================================
# [ì„¤ì •]
VIDEO_DIR = '/home/etri/data/video'      # ë¹„ë””ì˜¤ í´ë”
ENGINE_PATH = "x3d_xs_trt_fp16.ts"        # TorchScript/TRT ì—”ì§„ íŒŒì¼(.ts)
ITERATIONS = 50                          # ë¹„ë””ì˜¤ë‹¹ ë°˜ë³µ ì¸¡ì • íšŸìˆ˜(ì¸¡ì •ìš©)
WARMUP_ITERS = 20                        # ì›Œë°ì—… ë°˜ë³µ íšŸìˆ˜
PRINT_TOPK = 1                           # ê²°ê³¼ í™•ì¸ìš©
# ==========================================

device = "cuda"

def ensure_cuda():
    if not torch.cuda.is_available():
        print("âŒ CUDA ì‚¬ìš© ë¶ˆê°€. Jetson/CUDA í™˜ê²½ í™•ì¸ í•„ìš”.")
        sys.exit(1)

def load_labels():
    json_filename = "kinetics_classnames.json"
    if not os.path.exists(json_filename):
        urllib.request.urlretrieve(
            "https://dl.fbaipublicfiles.com/pyslowfast/dataset/class_names/kinetics_classnames.json",
            json_filename
        )
    with open(json_filename, "r") as f:
        kinetics_id_to_classname = {}
        for k, v in json.load(f).items():
            kinetics_id_to_classname[v] = str(k).replace('"', "")
    return kinetics_id_to_classname

def build_transform():
    mean = [0.45, 0.45, 0.45]
    std = [0.225, 0.225, 0.225]
    return ApplyTransformToKey(
        key="video",
        transform=Compose([
            UniformTemporalSubsample(13),          # T=13
            Lambda(lambda x: x / 255.0),
            NormalizeVideo(mean, std),
            ShortSideScale(size=182),
            CenterCropVideo(crop_size=(182, 182)),
        ]),
    )

@torch.no_grad()
def warmup(model, input_tensor, warmup_iters=WARMUP_ITERS):
    for _ in range(warmup_iters):
        _ = model(input_tensor)
    torch.cuda.synchronize()

@torch.no_grad()
def measure_inference_cuda_events(model, input_tensor, iters=ITERATIONS):
    """
    - per-iter latency: CUDA eventsë¡œ ì¸¡ì • (ms)
    - total time: CUDA eventsë¡œ ì¸¡ì • (ms)
    - throughput: iters / (total_ms/1000)
    """
    model.eval()

    # ì „ì²´ ì‹œê°„(throughputìš©)
    start_total = torch.cuda.Event(enable_timing=True)
    end_total = torch.cuda.Event(enable_timing=True)

    # per-iter latency ë¶„í¬(p50/p90/p99ìš©)
    starts = [torch.cuda.Event(enable_timing=True) for _ in range(iters)]
    ends   = [torch.cuda.Event(enable_timing=True) for _ in range(iters)]

    torch.cuda.synchronize()

    start_total.record()
    for i in range(iters):
        starts[i].record()
        _ = model(input_tensor)
        ends[i].record()
    end_total.record()

    torch.cuda.synchronize()

    # total ms
    total_ms = start_total.elapsed_time(end_total)

    # per-iter ms
    lat_ms = np.array([starts[i].elapsed_time(ends[i]) for i in range(iters)], dtype=np.float64)

    # í†µê³„
    mean_ms = float(lat_ms.mean())
    p50_ms  = float(np.percentile(lat_ms, 50))
    p90_ms  = float(np.percentile(lat_ms, 90))
    p99_ms  = float(np.percentile(lat_ms, 99))
    # throughput (clips/s) â€” total time ê¸°ë°˜ì´ ê°€ì¥ ì •í™•
    throughput = float(iters / (total_ms / 1000.0))

    return {
        "total_ms": float(total_ms),
        "mean_ms": mean_ms,
        "p50_ms": p50_ms,
        "p90_ms": p90_ms,
        "p99_ms": p99_ms,
        "throughput_clips_s": throughput,
    }

def predict_label(model, input_tensor, id2name):
    with torch.no_grad():
        preds = model(input_tensor)
        probs = torch.softmax(preds, dim=1)
        topk = probs.topk(PRINT_TOPK)
        top1_idx = int(topk.indices[0][0])
        return id2name.get(top1_idx, str(top1_idx))

def main():
    ensure_cuda()

    # 1) ëª¨ë¸ ë¡œë“œ
    print(f"ğŸ“‚ Loading Model from {ENGINE_PATH}...")
    if not os.path.exists(ENGINE_PATH):
        print("âŒ ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤!")
        sys.exit(1)

    model = torch.jit.load(ENGINE_PATH).eval().to(device)
    print("âœ… Model Loaded!")

    # 2) ë¼ë²¨ ë¡œë“œ
    kinetics_id_to_classname = load_labels()

    # 3) ì „ì²˜ë¦¬
    transform = build_transform()
    clip_duration = (13 * 6) / 30  # ê¸°ì¡´ ì„¤ì • ìœ ì§€ (T=13, stride=6, fps=30 ê°€ì •)

    # 4) ë¹„ë””ì˜¤ ëª©ë¡
    video_files = sorted(
        glob.glob(os.path.join(VIDEO_DIR, '*.mp4')) +
        glob.glob(os.path.join(VIDEO_DIR, '*.avi'))
    )
    if not video_files:
        print("âŒ ë¹„ë””ì˜¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        sys.exit(1)

    # 5) ì›Œë°ì—… (shape ë§ì¶˜ dummy)
    dummy = torch.randn(1, 3, 13, 182, 182, device=device, dtype=torch.float16)
    print(f"ğŸ”¥ Warming up... ({WARMUP_ITERS} iters)")
    warmup(model, dummy, warmup_iters=WARMUP_ITERS)
    print("âœ… Warm-up Done!\n")

    # ì¶œë ¥ í—¤ë”
    print(f"ğŸš€ Benchmark Start | Videos: {len(video_files)} | Iters/video: {ITERATIONS} | Batch=1")
    print("-" * 140)
    print(f"{'Filename':<35} | {'Preproc(ms)':<11} | {'Mean(ms)':<9} | {'P50':<7} | {'P90':<7} | {'P99':<7} | {'Throughput(clips/s)':<19} | {'Prediction':<20}")
    print("-" * 140)

    # ê¸€ë¡œë²Œ ëˆ„ì (ì¶”ë¡ ë§Œ)
    global_total_ms = 0.0
    global_total_iters = 0
    global_mean_list = []

    for video_path in video_files:
        filename = os.path.basename(video_path)

        try:
            # (A) ì „ì²˜ë¦¬ ì‹œê°„(ë””ì½”ë”©+transform) ì¸¡ì •: CPU wall time
            t0 = time.perf_counter()
            video = EncodedVideo.from_path(video_path)
            video_data = video.get_clip(start_sec=0, end_sec=clip_duration)
            video_data = transform(video_data)
            # ì…ë ¥ ì¤€ë¹„
            inputs = video_data["video"].to(device).half()
            inputs = inputs[None, ...]  # (1, C, T, H, W)
            torch.cuda.synchronize()  # ì „ì²˜ë¦¬ ì´í›„ GPU sync (ì•ˆì •ì ìœ¼ë¡œ ë¶„ë¦¬)
            t1 = time.perf_counter()
            preproc_ms = (t1 - t0) * 1000.0

            # (B) ì¶”ë¡  ì‹œê°„/ë¶„í¬ ì¸¡ì •: CUDA events
            stats = measure_inference_cuda_events(model, inputs, iters=ITERATIONS)

            # (C) ì˜ˆì¸¡ ë¼ë²¨(ì¸¡ì • í›„ 1íšŒë§Œ)
            pred_label = predict_label(model, inputs, kinetics_id_to_classname)

            print(f"{filename[:33]:<35} | "
                  f"{preproc_ms:<11.2f} | "
                  f"{stats['mean_ms']:<9.3f} | "
                  f"{stats['p50_ms']:<7.3f} | "
                  f"{stats['p90_ms']:<7.3f} | "
                  f"{stats['p99_ms']:<7.3f} | "
                  f"{stats['throughput_clips_s']:<19.2f} | "
                  f"{pred_label[:20]:<20}")

            global_total_ms += stats["total_ms"]
            global_total_iters += ITERATIONS
            global_mean_list.append(stats["mean_ms"])

        except Exception as e:
            print(f"{filename[:33]:<35} | Error: {e}")

    print("-" * 140)
    if global_total_iters > 0:
        global_throughput = global_total_iters / (global_total_ms / 1000.0)
        global_mean_ms = float(np.mean(global_mean_list)) if global_mean_list else float("nan")
        print(f"âœ… GLOBAL (Inference-only, CUDA events)")
        print(f"   - Total clips: {global_total_iters}")
        print(f"   - Total inference time: {global_total_ms:.2f} ms")
        print(f"   - Global throughput: {global_throughput:.2f} clips/sec")
        print(f"   - Avg of per-video mean latency: {global_mean_ms:.3f} ms/clip")
        print("   * Note: ì „ì²˜ë¦¬ ì‹œê°„ì€ ìœ„ í‘œ Preproc(ms)ì— ë³„ë„ ì¸¡ì •ë¨(ì¶”ë¡  throughputì— í¬í•¨ X).")
    else:
        print("âŒ ì¸¡ì •ëœ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
    print("-" * 140)

if __name__ == "__main__":
    main()
