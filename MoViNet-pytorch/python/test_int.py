import torch
import cv2
import os
import glob
import sys
import time
import argparse
import urllib.request
import numpy as np
from collections import deque
from datetime import datetime
from torch2trt import TRTModule

# === ì„¤ì •: ì¸í„°ë™í‹°ë¸Œ ëª¨ë“œ ===
def get_user_input():
    print("\n" + "="*40)
    print("   MoViNet TensorRT INT8 Benchmark")
    print("="*40)
    print(" 0: MoViNet-A0 (Fastest)")
    print(" 1: MoViNet-A1 (Balanced)")
    print(" 2: MoViNet-A2 (Higher Accuracy)") # A2 Option added
    
    while True:
        choice = input(">> Select Model (0, 1, 2): ").strip()
        if choice in ['0', '1', '2']:
            return f"a{choice}"
        print("âŒ 0, 1, 2 ì¤‘ í•˜ë‚˜ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")

# === ë©”ì¸ ì½”ë“œ ===
if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument('--model', type=str, choices=['a0', 'a1', 'a2'], help='ëª¨ë¸ ì„ íƒ')
    parser.add_argument('--source', type=str, help='ì´ë¯¸ì§€ í´ë” ê²½ë¡œ')
    args = parser.parse_args()

    # 1. ëª¨ë¸ ì„ íƒ
    if args.model and args.source:
        selected_model = args.model
        source_folder = args.source
    else:
        selected_model = get_user_input()
        print("\n" + "="*40)
        print("   ë¶„ì„í•  ì´ë¯¸ì§€ í´ë” ê²½ë¡œ ì…ë ¥")
        print("="*40)
        while True:
            source_folder = input(">> í´ë” ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”: ").strip()
            source_folder = source_folder.replace("'", "").replace('"', "")
            if os.path.exists(source_folder): break
            print(f"âŒ í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    # 2. ì„¤ì • ë³€ìˆ˜ (A2 resolution updated to 224)
    if selected_model == 'a0': 
        IMG_SIZE = 172
    elif selected_model == 'a1': 
        IMG_SIZE = 172
    elif selected_model == 'a2': 
        IMG_SIZE = 224
    
    # â˜… ì¤‘ìš”: convert_int8.pyì—ì„œ ì„¤ì •í•œ í”„ë ˆì„ ìˆ˜ì™€ ë™ì¼í•´ì•¼ í•©ë‹ˆë‹¤.
    CLIP_frames = 8  
    
    LABEL_URL = "https://raw.githubusercontent.com/tensorflow/models/master/official/projects/movinet/files/kinetics_600_labels.txt"
    LABEL_FILE = "kinetics_600_labels.txt"

    # â˜… TensorRT INT8 ì—”ì§„ íŒŒì¼ ê²½ë¡œ
    ENGINE_PATH = f"movinet_{selected_model}_trt_int8.pth"

    if not os.path.exists(ENGINE_PATH):
        print(f"âŒ INT8 ì—”ì§„ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {ENGINE_PATH}")
        print(f"ğŸ‘‰ ë¨¼ì € 'convert_int8.py'ë¥¼ ì‹¤í–‰í•˜ì—¬ {selected_model.upper()} ì—”ì§„ì„ ìƒì„±í•´ì£¼ì„¸ìš”.")
        sys.exit()

    # === [Result Path & Timestamp] ===
    RESULT_DIR = os.path.join(os.getcwd(), "result")
    os.makedirs(RESULT_DIR, exist_ok=True)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    RESULT_FILE = os.path.join(RESULT_DIR, f"benchmark_trt_INT8_result_{selected_model}_{timestamp}.txt")

    # 3. ì´ë¯¸ì§€ ê²€ìƒ‰
    print(f"\nğŸ” '{source_folder}' ì´ë¯¸ì§€ ê²€ìƒ‰ ì¤‘...")
    image_files = []
    for ext in ['*.png', '*.jpg', '*.jpeg']:
        image_files.extend(glob.glob(os.path.join(source_folder, '**', ext), recursive=True))
    
    image_files.sort()

    if not image_files:
        print("âŒ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        sys.exit()
    print(f"âœ… ì´ {len(image_files)}ì¥ ë°œê²¬.")

    # 4. ë¼ë²¨ ë¡œë“œ
    if not os.path.exists(LABEL_FILE):
        urllib.request.urlretrieve(LABEL_URL, LABEL_FILE)
    with open(LABEL_FILE, "r") as f:
        labels = [line.strip() for line in f.readlines()]

    # 5. TensorRT ëª¨ë¸ ë¡œë“œ
    print(f"ğŸ”„ Loading INT8 Engine: {ENGINE_PATH} ...")
    try:
        model_trt = TRTModule()
        model_trt.load_state_dict(torch.load(ENGINE_PATH))
        model_trt = model_trt.cuda()
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        sys.exit()

    print(f"ğŸ“Š ëª¨ë¸ íƒ€ì…: MoViNet-{selected_model.upper()} TensorRT Engine (INT8)")

    # 6. ì¶”ë¡  ë° FPS ì¸¡ì •
    print(f"ğŸš€ ë²¤ì¹˜ë§ˆí¬ ì‹œì‘... (ê²°ê³¼ëŠ” '{RESULT_FILE}'ì— ì €ì¥)")
    
    frame_buffer = deque(maxlen=CLIP_frames)

    # GPU ì›Œë°ì—…
    print("ğŸ”¥ GPU ì›Œë°ì—… ì¤‘...")
    dummy_input = torch.randn(1, 3, CLIP_frames, IMG_SIZE, IMG_SIZE).cuda()
    for _ in range(10):
        _ = model_trt(dummy_input)
    torch.cuda.synchronize()

    results_buffer = []
    start_time = time.time()
    
    with torch.no_grad():
        for i, img_path in enumerate(image_files):
            frame = cv2.imread(img_path)
            if frame is None: continue

            img_resized = cv2.resize(frame, (IMG_SIZE, IMG_SIZE))
            input_tensor = torch.from_numpy(cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB)).float() / 255.0
            input_tensor = input_tensor.permute(2, 0, 1)
            
            frame_buffer.append(input_tensor)

            # ë²„í¼ê°€ ë¶€ì¡±í•  ê²½ìš° ì²« í”„ë ˆì„ìœ¼ë¡œ ì±„ì›€
            while len(frame_buffer) < CLIP_frames:
                frame_buffer.append(input_tensor)

            input_batch = torch.stack(list(frame_buffer), dim=1).unsqueeze(0).cuda()

            # ì¶”ë¡ 
            prediction = model_trt(input_batch)
            
            probs = torch.nn.functional.softmax(prediction[0], dim=0)
            top_prob, top_class = torch.topk(probs, 1)

            action = labels[top_class.item()]
            score = top_prob.item() * 100
            
            if i % 10 == 0:
                current_fps = (i + 1) / (time.time() - start_time)
                print(f"[{i}/{len(image_files)}] Processing... {current_fps:.1f} FPS", end='\r')

            folder_name = os.path.basename(os.path.dirname(img_path))
            file_name = os.path.basename(img_path)
            results_buffer.append(f"{folder_name:<20} | {file_name:<30} | {action:<25} | {score:.1f}%")

    torch.cuda.synchronize()
    end_time = time.time()

    # 7. ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°
    total_time = end_time - start_time
    fps = len(image_files) / total_time

    print(f"\nâœ… ì™„ë£Œ! ì´ ì†Œìš”ì‹œê°„: {total_time:.2f}ì´ˆ")
    print(f"âš¡ í‰ê·  FPS: {fps:.2f} frames/sec")

    # 8. ê²°ê³¼ íŒŒì¼ ì €ì¥
    with open(RESULT_FILE, "w", encoding='utf-8') as f:
        f.write(f"=== MoViNet TensorRT INT8 Benchmark Report ===\n")
        f.write(f"Date: {timestamp}\n")
        f.write(f"Model: MoViNet-{selected_model.upper()} (INT8 Quantized)\n")
        f.write(f"Input Shape: (1, 3, {CLIP_frames}, {IMG_SIZE}, {IMG_SIZE})\n")
        f.write(f"Total Images: {len(image_files)}\n")
        f.write(f"Average FPS: {fps:.2f}\n")
        f.write("="*90 + "\n")
        f.write(f"{'Folder':<20} | {'File':<30} | {'Prediction':<25} | {'Score'}\n")
        f.write("-" * 90 + "\n")
        for line in results_buffer:
            f.write(line + "\n")

    print(f"ğŸ“„ ë¦¬í¬íŠ¸ ì €ì¥ ì™„ë£Œ: {RESULT_FILE}")