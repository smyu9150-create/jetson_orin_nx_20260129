import torch
import cv2
import glob
import os
import random
from torch2trt import torch2trt, DEFAULT_CALIBRATION_ALGORITHM
from movinets.models import MoViNet
from movinets.config import _C

# ==========================================
# 1. ì„¤ì •
# ==========================================
MODEL_VARIANT = 'a2'


# ==========================================
# 3. ëª¨ë¸ ë° ë°ì´í„°ì…‹ ì¤€ë¹„
# ==========================================
if MODEL_VARIANT == 'a0':
    config = _C.MODEL.MoViNetA0
elif MODEL_VARIANT == 'a1':
    config = _C.MODEL.MoViNetA1
    IMG_SIZE = 172
elif MODEL_VARIANT == 'a2':
    config = _C.MODEL.MoViNetA2
    IMG_SIZE = 224


FRAMES = 8
CALIBRATION_BATCHES = 100  # ë³´ì •ì— ì‚¬ìš©í•  ë°°ì¹˜ ìˆ˜ (ë§ì„ìˆ˜ë¡ ì •í™•ë„ ìœ ì§€, ë³€í™˜ ì‹œê°„ ì¦ê°€)
DATA_PATH = "result/images" # â˜… ì‹¤ì œ ì´ë¯¸ì§€ê°€ ìˆëŠ” í´ë” ê²½ë¡œë¡œ ìˆ˜ì •í•˜ì„¸ìš”!

# ê²½ë¡œê°€ ì—†ìœ¼ë©´ ì‚¬ìš©ìì—ê²Œ ì…ë ¥ì„ ë°›ë„ë¡ í•¨
if not os.path.exists(DATA_PATH):
    print(f"âš ï¸ ê²½ê³ : '{DATA_PATH}' í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤.")
    DATA_PATH = input(">> í•™ìŠµ/í…ŒìŠ¤íŠ¸ìš© ì´ë¯¸ì§€ê°€ ìˆëŠ” í´ë” ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”: ").strip().replace("'", "").replace('"', "")

print(f"[{MODEL_VARIANT}] INT8 ë³€í™˜ ì¤€ë¹„ ì¤‘... í•´ìƒë„: {IMG_SIZE}x{IMG_SIZE}")

# ==========================================
# 2. Calibration Dataset í´ë˜ìŠ¤ ì •ì˜
# ==========================================
# ì‹¤ì œ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì—¬ TensorRTì— ê³µê¸‰í•˜ëŠ” ì—­í• 
class MoViNetCalibrationDataset:
    def __init__(self, folder_path, img_size, frames, num_batches):
        self.img_files = sorted(glob.glob(os.path.join(folder_path, '**', '*.jpg'), recursive=True) + 
                                glob.glob(os.path.join(folder_path, '**', '*.png'), recursive=True))
        self.img_size = img_size
        self.frames = frames
        self.num_batches = num_batches
        
        if len(self.img_files) < frames:
            raise ValueError(f"ì´ë¯¸ì§€ê°€ ë„ˆë¬´ ì ìŠµë‹ˆë‹¤. ìµœì†Œ {frames}ì¥ ì´ìƒ í•„ìš”í•©ë‹ˆë‹¤.")
            
        print(f"âœ… ì´ {len(self.img_files)}ì¥ì˜ ì´ë¯¸ì§€ë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. ë³´ì • ë°ì´í„°ì…‹ êµ¬ì„± ì¤‘...")

    def __len__(self):
        return self.num_batches

    def __getitem__(self, idx):
        # ëœë¤í•˜ê²Œ ì—°ì†ëœ 8ì¥ì˜ ì´ë¯¸ì§€ë¥¼ ë½‘ì•„ì„œ ë°°ì¹˜ êµ¬ì„±
        start_idx = random.randint(0, len(self.img_files) - self.frames - 1)
        clip = []
        for i in range(self.frames):
            img = cv2.imread(self.img_files[start_idx + i])
            img = cv2.resize(img, (self.img_size, self.img_size))
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            clip.append(img)
        
        # (Frames, H, W, C) -> (C, Frames, H, W) -> (1, C, Frames, H, W)
        tensor = torch.from_numpy(np.array(clip)).float() / 255.0
        tensor = tensor.permute(3, 0, 1, 2).unsqueeze(0).cuda()
        
        # torch2trtëŠ” ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ì…ë ¥ì„ ë°›ìŒ
        return [tensor]

# numpy ì„í¬íŠ¸ í•„ìš” (ìƒë‹¨ì— ì¶”ê°€ ì•ˆë˜ì–´ìˆë‹¤ë©´)
import numpy as np



# ëª¨ë¸ ë¡œë“œ
model = MoViNet(config, causal=False, pretrained=True).cuda().eval()

# ë³´ì • ë°ì´í„°ì…‹ ìƒì„±
try:
    calib_dataset = MoViNetCalibrationDataset(DATA_PATH, IMG_SIZE, FRAMES, CALIBRATION_BATCHES)
except Exception as e:
    print(f"âŒ ë°ì´í„°ì…‹ ì—ëŸ¬: {e}")
    exit()

# ë”ë¯¸ ì…ë ¥ (ì…ë ¥ í¬ê¸° ì •ì˜ìš©)
dummy_input = torch.ones((1, 3, FRAMES, IMG_SIZE, IMG_SIZE)).cuda()

# ==========================================
# 4. INT8 ë³€í™˜ ì‹¤í–‰
# ==========================================
print(f"ğŸš€ TensorRT INT8 ë³€í™˜ ì‹œì‘... (ë³´ì • ì‘ì—…ìœ¼ë¡œ ì¸í•´ ì‹œê°„ì´ ì¡°ê¸ˆ ê±¸ë¦½ë‹ˆë‹¤)")
print(f" - Calibration Batches: {CALIBRATION_BATCHES}")

model_trt = torch2trt(
    model,
    [dummy_input],
    fp16_mode=True,       # FP16ë„ ì¼œì•¼ ì„±ëŠ¥ ìµœì í™”ë¨
    int8_mode=True,       # â˜… INT8 ëª¨ë“œ í™œì„±í™”
    int8_calib_dataset=calib_dataset, # ë³´ì • ë°ì´í„° ê³µê¸‰
    int8_calib_algorithm=DEFAULT_CALIBRATION_ALGORITHM,
    max_workspace_size=1<<25
)

# ==========================================
# 5. ì €ì¥
# ==========================================
save_name = f'movinet_{MODEL_VARIANT}_trt_int8.pth'
torch.save(model_trt.state_dict(), save_name)

print(f"\nâœ… ì„±ê³µ! INT8 ëª¨ë¸ ì €ì¥ë¨: {save_name}")
