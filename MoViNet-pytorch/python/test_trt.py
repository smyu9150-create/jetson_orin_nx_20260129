import torch
import cv2
import os
import glob
import sys
import time
import argparse
import urllib.request
import numpy as np
from collections import deque
from datetime import datetime
from torch2trt import TRTModule

import tensorrt as trt

LABEL_URL = "https://raw.githubusercontent.com/tensorflow/models/master/official/projects/movinet/files/kinetics_600_labels.txt"
LABEL_FILE = "kinetics_600_labels.txt"


def get_user_input():
    print("\n" + "=" * 40)
    print("   MoViNet TensorRT Benchmark")
    print("=" * 40)
    print(" 0: MoViNet-A0 (Fastest)")
    print(" 1: MoViNet-A1 (Balanced)")
    print(" 2: MoViNet-A2 (Most Accurate)")

    while True:
        choice = input(">> Select Model (0, 1, 2): ").strip()
        if choice in ["0", "1", "2"]:
            return f"a{choice}"
        print("âŒ 0, 1, 2 ì¤‘ í•˜ë‚˜ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")


def find_images(source_folder: str):``
    image_files = []
    for ext in ["*.png", "*.jpg", "*.jpeg"]:
        image_files.extend(glob.glob(os.path.join(source_folder, "**", ext), recursive=True))
    image_files.sort()
    return image_files


def load_labels():
    if not os.path.exists(LABEL_FILE):
        print("â¬‡ï¸ ë¼ë²¨ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì¤‘...")
        urllib.request.urlretrieve(LABEL_URL, LABEL_FILE)

    with open(LABEL_FILE, "r", encoding="utf-8") as f:
        labels = [line.strip() for line in f.readlines()]
    return labels


def preprocess_frame_bgr(frame_bgr, img_size: int):
    # Resize
    img = cv2.resize(frame_bgr, (img_size, img_size), interpolation=cv2.INTER_LINEAR)
    # BGR -> RGB
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    # float32, 0~1
    img = img.astype(np.float32) / 255.0
    # (H,W,C) -> (C,H,W)
    img = np.transpose(img, (2, 0, 1))
    return img  # numpy float32 (3,H,W)


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--model", type=str, choices=["a0", "a1", "a2"], help="ëª¨ë¸ ì„ íƒ")
    parser.add_argument("--source", type=str, help="ì´ë¯¸ì§€ í´ë” ê²½ë¡œ")
    parser.add_argument("--engine", type=str, default=None, help="ì—”ì§„ ê²½ë¡œ ì§ì ‘ ì§€ì • (ê¸°ë³¸: movinet_{model}_trt_fp16.pth)")
    parser.add_argument("--clip_frames", type=int, default=8, help="í´ë¦½ í”„ë ˆì„ ìˆ˜ (ì—”ì§„ ë³€í™˜ ì‹œ ê°’ê³¼ ë™ì¼í•´ì•¼ í•¨)")
    parser.add_argument("--warmup", type=int, default=10, help="GPU ì›Œë°ì—… ë°˜ë³µ íšŸìˆ˜")
    parser.add_argument("--log_every", type=int, default=10, help="ëª‡ ì¥ë§ˆë‹¤ ì§„í–‰ìƒí™© ì¶œë ¥í• ì§€")
    parser.add_argument("--max_images", type=int, default=0, help="0ì´ë©´ ì „ì²´, ê·¸ ì™¸ ìˆ«ìë©´ í•´ë‹¹ ê°œìˆ˜ê¹Œì§€ë§Œ ì²˜ë¦¬")
    parser.add_argument("--no_postprocess", action="store_true", help="softmax/topk/postprocess ìƒëµ(ì†ë„ ì¸¡ì •ìš©)")
    parser.add_argument("--save_scores", action="store_true", help="ê²°ê³¼ íŒŒì¼ì— ì˜ˆì¸¡/scoreê¹Œì§€ ì €ì¥ (ê¸°ë³¸ì€ ì €ì¥)")
    args = parser.parse_args()

    # 1) ëª¨ë¸/ì†ŒìŠ¤ ì…ë ¥
    if args.model and args.source:
        selected_model = args.model
        source_folder = args.source
    else:
        selected_model = get_user_input()
        print("\n" + "=" * 40)
        print("   ë¶„ì„í•  ì´ë¯¸ì§€ í´ë” ê²½ë¡œ ì…ë ¥")
        print("=" * 40)
        while True:
            source_folder = input(">> í´ë” ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”: ").strip()
            source_folder = source_folder.replace("'", "").replace('"', "")
            if os.path.exists(source_folder):
                break
            print("âŒ í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    # 2) IMG_SIZE (ì—”ì§„ ë³€í™˜ ê°’ê³¼ ë™ì¼í•´ì•¼ í•¨)
    if selected_model in ["a0", "a1"]:
        img_size = 172
    else:
        img_size = 224

    clip_frames = args.clip_frames

    # 3) ì—”ì§„ ê²½ë¡œ
    engine_path = args.engine if args.engine else f"movinet_{selected_model}_trt_fp16.pth"
    if not os.path.exists(engine_path):
        print(f"âŒ ì—”ì§„ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {engine_path}")
        print("ğŸ‘‰ ë¨¼ì € convert.pyë¡œ ì—”ì§„ì„ ìƒì„±í•˜ì„¸ìš”.")
        sys.exit(1)

    # 4) ê²°ê³¼ íŒŒì¼ ê²½ë¡œ
    result_dir = os.path.join(os.getcwd(), "result")
    os.makedirs(result_dir, exist_ok=True)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    result_file = os.path.join(result_dir, f"benchmark_trt_{selected_model}_{timestamp}.txt")

    # 5) ì´ë¯¸ì§€ ë¡œë”©
    print(f"\nğŸ” '{source_folder}' ì´ë¯¸ì§€ ê²€ìƒ‰ ì¤‘...")
    image_files = find_images(source_folder)
    if not image_files:
        print("âŒ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        sys.exit(1)

    if args.max_images and args.max_images > 0:
        image_files = image_files[: args.max_images]

    print(f"âœ… ì´ {len(image_files)}ì¥ ë°œê²¬.")

    # 6) ë¼ë²¨
    labels = load_labels()

    # 7) TRT ëª¨ë¸ ë¡œë“œ
    print(f"ğŸ”„ Loading TensorRT Engine: {engine_path} ...")
    try:
        model_trt = TRTModule()
        model_trt.load_state_dict(torch.load(engine_path, weights_only=False))
        model_trt = model_trt.cuda().eval()
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        sys.exit(1)

    print("ğŸ“Š ëª¨ë¸ íƒ€ì…: TensorRT Engine (FP16)")
    print(f"ğŸš€ ë²¤ì¹˜ë§ˆí¬ ì‹œì‘... (ê²°ê³¼ëŠ” '{result_file}'ì— ì €ì¥)")

    # 8) ì›Œë°ì—…
    print("ğŸ”¥ GPU ì›Œë°ì—… ì¤‘...")
    dummy_input = torch.randn(1, 3, clip_frames, img_size, img_size, device="cuda", dtype=torch.float32)
    with torch.no_grad():
        for _ in range(args.warmup):
            _ = model_trt(dummy_input)
    torch.cuda.synchronize()

    # 9) ë²„í¼(ìŠ¬ë¼ì´ë”© ìœˆë„ìš°)
    frame_buffer = deque(maxlen=clip_frames)

    # 10) ì„±ëŠ¥ ì¸¡ì •ìš© (inference-only)
    starter = torch.cuda.Event(enable_timing=True)
    ender = torch.cuda.Event(enable_timing=True)
    infer_ms_list = []

    # 11) ê²°ê³¼ ì €ì¥ìš©
    results_buffer = []

    # 12) ì‹¤ì‹œê°„ FPS ì¶œë ¥ìš©
    start_time = time.time()
    last_print_t = start_time
    last_print_i = 0

    # 13) pinned memory ë²„í¼ (H2D ë³µì‚¬ ì•½ê°„ ê°œì„ )
    #    (3,H,W) í˜•íƒœ numpyë¥¼ torch tensorë¡œ ë°”ê¿”ì„œ CPUì— pin í›„ GPUë¡œ non_blocking ì „ì†¡
    use_post = not args.no_postprocess

    with torch.no_grad():
        for i, img_path in enumerate(image_files):
            frame = cv2.imread(img_path)
            if frame is None:
                continue

            np_chw = preprocess_frame_bgr(frame, img_size)  # (3,H,W) float32
            cpu_tensor = torch.from_numpy(np_chw)  # CPU float32
            # pin memory (ê°€ëŠ¥í•œ ê²½ìš°)
            cpu_tensor = cpu_tensor.pin_memory()

            # ë²„í¼ì— CPU í…ì„œ ì €ì¥ (GPU ë©”ëª¨ë¦¬ ì ˆì•½)
            frame_buffer.append(cpu_tensor)

            # ì´ˆê¸° íŒ¨ë”©
            while len(frame_buffer) < clip_frames:
                frame_buffer.append(cpu_tensor)

            # (clip_frames, 3, H, W) -> (3, clip_frames, H, W)
            # stack dim=0: (T, C, H, W)
            clip_cpu = torch.stack(list(frame_buffer), dim=0)         # (T, C, H, W)
            clip_cpu = clip_cpu.permute(1, 0, 2, 3).contiguous()      # (C, T, H, W)
            input_cpu = clip_cpu.unsqueeze(0)                         # (1, C, T, H, W)

            # H2D (non_blocking)
            input_batch = input_cpu.to(device="cuda", non_blocking=True)

            # ===== Inference-only timing (CUDA event) =====
            starter.record()
            prediction = model_trt(input_batch)
            ender.record()
            torch.cuda.synchronize()
            infer_ms = starter.elapsed_time(ender)
            infer_ms_list.append(infer_ms)

            action = "N/A"
            score = 0.0

            if use_post:
                probs = torch.nn.functional.softmax(prediction[0], dim=0)
                top_prob, top_class = torch.topk(probs, 1)
                idx = top_class.item()
                action = labels[idx] if 0 <= idx < len(labels) else f"class_{idx}"
                score = float(top_prob.item()) * 100.0

            # ë¡œê¹…
            if args.log_every > 0 and (i % args.log_every == 0) and i > 0:
                now = time.time()
                dt = now - last_print_t
                inst_fps = (i - last_print_i) / dt if dt > 0 else 0.0
                print(f"[{i}/{len(image_files)}] Processing... {inst_fps:.1f} FPS", end="\r")
                last_print_t = now
                last_print_i = i

            # ê²°ê³¼ ê¸°ë¡
            folder_name = os.path.basename(os.path.dirname(img_path))
            file_name = os.path.basename(img_path)

            if args.no_postprocess:
                results_buffer.append(f"{folder_name:<20} | {file_name:<30} | {'(postprocess off)':<25} | {'-':>6}")
            else:
                results_buffer.append(f"{folder_name:<20} | {file_name:<30} | {action:<25} | {score:5.1f}%")

    torch.cuda.synchronize()
    end_time = time.time()

    # 14) pipeline FPS (ì „ì²´)
    total_time = end_time - start_time
    pipeline_fps = len(image_files) / total_time if total_time > 0 else 0.0

    # 15) inference-only FPS
    avg_infer_ms = float(np.mean(infer_ms_list)) if infer_ms_list else 0.0
    infer_fps = (1000.0 / avg_infer_ms) if avg_infer_ms > 0 else 0.0

    print("\nâœ… ì™„ë£Œ!")
    print(f"ğŸ•’ ì´ ì†Œìš”ì‹œê°„(pipeline): {total_time:.2f}ì´ˆ")
    print(f"âš¡ í‰ê·  FPS(pipeline): {pipeline_fps:.2f} frames/sec")
    print(f"âš¡ í‰ê·  FPS(inference-only): {infer_fps:.2f} clips/sec (avg {avg_infer_ms:.3f} ms/clip)")

    # 16) ì €ì¥
    with open(result_file, "w", encoding="utf-8") as f:
        f.write("=== MoViNet TensorRT Benchmark Report ===\n")
        f.write(f"Date: {timestamp}\n")
        f.write(f"Model: MoViNet-{selected_model.upper()} (TensorRT FP16 via torch2trt)\n")
        f.write(f"Engine: {engine_path}\n")
        f.write(f"Input Shape: (1, 3, {clip_frames}, {img_size}, {img_size})\n")
        f.write(f"Total Images: {len(image_files)}\n")
        f.write(f"Pipeline Time (sec): {total_time:.4f}\n")
        f.write(f"Average FPS (pipeline): {pipeline_fps:.4f}\n")
        f.write(f"Average Inference (ms/clip): {avg_infer_ms:.4f}\n")
        f.write(f"Average FPS (inference-only): {infer_fps:.4f}\n")
        f.write("=" * 100 + "\n")
        f.write(f"{'Folder':<20} | {'File':<30} | {'Prediction':<25} | {'Score'}\n")
        f.write("-" * 100 + "\n")
        for line in results_buffer:
            f.write(line + "\n")

    print(f"ğŸ“„ ë¦¬í¬íŠ¸ ì €ì¥ ì™„ë£Œ: {result_file}")


if __name__ == "__main__":
    main()
